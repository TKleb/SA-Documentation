\label{sec:testing}
\subsection{Testing}
This chapter describes how the quality of the challenges was determined and the feedback was evaluated. \\
The labs were tested by many different participants. This testing was done to ensure the challenges were solvable and understandable for the intended purpose. The testing can be divided into two parts.

\subsubsection{Internal Tests}
After every challenge was completed and uploaded to the Hacking-Lab platform, the creator checked the challenge again. After the creator finished his testing, he signaled the other students from the group to test the challenge. Any questions, mistakes or feedback from these tests were immediately reported to the creator. He then decided which parts he had to change. Additionally at the next supervisor meeting the challenge was presented and the supervisor was also able to give feedback to the challenge.

\subsubsection{Testing with third-party students}
In order to get realistic feedback from students, we asked cybersecurity students in their fifth semester to solve the labs and provide feedback. This feedback was collected using Google Forms. This tool allows to create simple surveys, which can then be analyzed in graphs automatically. \\
Only some of the challenges were solved by this group. The feedback received was helpful. However, since many of these students were also busy with a SA, it was a bit difficult for them to find the motivation to solve them thoroughly. Testing the labs meant a significant amount of work and therefore these tests were only done by a few individuals for all the challenges.

\subsubsection{Feedback}
The challenges were perceived as educating and easy to follow by the testing participants. The main takeaway from these tests were the following points:
\begin{itemize}
    \item Challenges are clear and interesting
    \item Challenges teach concepts in a fun way
    \item The time requirements for each challenge vary by much
  \end{itemize}

\subsubsection{Conclusion}
The feedback was mostly positive. Most of the feedback mentioned typing errors or some errors with setting up the challenges on Hacking-Lab.com. Some feedback also mentioned unprecise steps in the solutions. They were very useful to create the challenges in a way which should be understood by other students. \\
But we also think that our testing process could need some refining. We didn't really have a broad spectrum of knowledge and motivation in our testing participants because they had to do it in their leisure time. This way we only got very motivated students, who probably also had way more knowledge than the average one. In future projects we should strive to achieve a more normalized testing group by asking to be able to test some challenges in a security class or similar.
